---
title: "ZeRO stage 2"
date:   2020-03-13
excerpt: "Reduce memory footprint to enable training 10B models without model parallelism!"
---

# Zero Stage 2
* Reduce memory footprint of gradients
* Train larger models: e.g., 10B parameters on 32GPUs without model parallelism
* Train larger batch sizes

# Further updates coming soon!
